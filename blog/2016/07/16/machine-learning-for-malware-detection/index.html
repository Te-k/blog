<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta property="og:title" content=" Machine learning for malware detection &middot;  Tek&#39;s blog" />
<meta property="og:site_name" content="Tek&#39;s blog" />
<meta property="og:url" content="https://www.randhome.io/blog/2016/07/16/machine-learning-for-malware-detection/" />


    <meta property="og:type" content="article" />
    <meta property="og:article:published_time" content="2016-07-16T12:52:42&#43;02:00" />
    

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@http://twitter.com/tenacioustek" />
    <meta name="twitter:creator" content="@http://twitter.com/tenacioustek" />
    <meta name="twitter:title" content="Machine learning for malware detection" />
    <meta name="twitter:description" content="" />
    <meta name="twitter:url" content="https://www.randhome.io/blog/2016/07/16/machine-learning-for-malware-detection/" />


<title> Machine learning for malware detection &middot;  Tek&#39;s blog</title>


    <meta name="description" content="" />


<meta name="p:domain_verify" content="fc173d84e3a4de948ed4bda2908afd3e"/>
<meta name="HandheldFriendly" content="True" />
<meta name="MobileOptimized" content="320" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />





<link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,700italic,300,700' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Bree+Serif' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://www.randhome.io/css/pure-min.css">


    <link rel="stylesheet" href="https://www.randhome.io/css/grids-responsive-min.css">

<link rel="stylesheet" href="https://www.randhome.io/css/crisp.css">
<link rel="stylesheet" href="https://www.randhome.io/css/rrssb.css">
<link rel="stylesheet" href="https://www.randhome.io/css/highlight/sunburst.css">







<link rel="canonical" href="https://www.randhome.io/blog/2016/07/16/machine-learning-for-malware-detection/" />


    


    </head>
    <div id="layout" class="pure-g">
        <div class="sidebar pure-u-1 pure-u-md-1-6">
            <div class="header">
    <div class="title">
        <h1><a href="https://www.randhome.io/">Tek&#39;s blog</a></h1>
        <p class="lead">Random Security Stuff</p>
        
    </div>
    <div class="logo">
        
        
            
                <a id="logo" href="https://www.randhome.io/"><img src="/avatar2.png" alt="Tek&#39;s blog" /></a>
            
        
    </div>

    <ul class="sidebar-menu">
        
            <li class="sidebar-menu-item"><a href="https://www.randhome.io/references/">#references</a></li>
        
            <li class="sidebar-menu-item"><a href="https://www.randhome.io/about/">#whoami</a></li>
        
    </ul>

    <div id="follow-icons">
        
        <a href="http://twitter.com/tenacioustek" target="_blank" rel="me"><i class="fa fa-twitter-square fa-3x"></i></a>
        
        <a href="http://github.com/Te-k" target="_blank" rel="me"><i class="fa fa-github-square fa-3x"></i></a>
        
        
        
        <a href="https://keybase.io/tekkk" target="_blank"><i class="fa fa-key fa-3x"></i></a>
        <a href="https://www.randhome.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
    </div>

    
        <div class="cc">
            
            
            
            
            
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a>
            
        </div>
    
</div>

        </div>
        <div class="content pure-u-1 pure-u-md-5-6">
            <div class="article singlepage" id="" class="post">
                <div class="post-stamp">
                    <h1 class="post-title">Machine learning for malware detection</h1>
                    <span class="post-date">Jul 16, 2016 &middot; 9 minute read</span>
                    
                        <span class="taglist">
                            <a class="label" href="https://www.randhome.io/categories/malware">malware</a> <a class="label" href="https://www.randhome.io/categories/machine-learning">machine learning</a> 
                        </span>
                    

                    <span class="taglist">
                    
                    </span>
                </div>
                

<p>Plop,</p>

<p>I have been reading many articles about Machine Learning recently, and it seems to be the new hype technology so I wanted to play a bit with these algorithms to better understand the principles behind it. If you don&rsquo;t know machine learning, you should to read this <a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">awesome article</a> or <a href="https://redshiftzero.github.io/2015/08/29/Manipulation-and-Machine-Learning/">this one</a>. This article was largely inspired by <a href="https://blog.socialcops.com/engineering/machine-learning-python">this one which analyze the Titanic data</a>.</p>

<h2 id="machine-learning-and-classification">Machine Learning and Classification</h2>

<p>So the idea of machine learning is to let the algorithm learn by itself the best parameters from data in order to make good predictions. There are many different applications, in our case we will consider using machine learning algorithm to classify binaries between legitimate and malicious binaries. This idea is <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=924286&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D924286">not</a> <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=1297538&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D1297538">new</a> and Adobe has even released a tool called <a href="https://github.com/adobe-security/Malware-classifier">Adobe Malware Classifier</a> at <a href="https://www.blackhat.com/html/webcast/webcast-2012-polymorphicmalware.html">Black Hat 2012</a> but it will be a nice exercice to see how to use machine learning.</p>

<p>Here is the plan that we will follow :</p>

<ul>
<li>Extract as many features as we can from binaries to have a good training data set. The features have to be integers or floats to be usable by the algorithms</li>
<li>Identify the best features for the algorithm : we should select the information that best allows to differenciate legitimate files from malware.</li>
<li>Choose a classification algorithm</li>
<li>Test the efficiency of the algorithm and identify the False Positive/False negative rate</li>
</ul>


<figure >
    
        <img src="/media/doctor5.jpg" />
    
    
    <figcaption>
        <h4>Let&#39;s go!</h4>
        
    </figcaption>
    
</figure>


<h2 id="feature-extraction-from-binaries">Feature Extraction from binaries</h2>

<p>As I said earlier, machine learning only uses integer or float data as features for detection, but it is not a big deal as most <a href="https://manalyzer.org/report/1e27184759cc4099c0da73b152408281">PE parameters</a> are integers (field size, addresses, parameters&hellip;). So I extracted all the PE parameters I could by using pefile, and considered especially the one that are relevant for identifying malware, like the entropy of section for packer detection. As we can only have a fix list of feature (and not one per section), I extracted the Mean, Minimum and Maximum of entropy for sections and resources.</p>

<p>Here is the final list of feature extracted : <em>Name, md5, Machine, SizeOfOptionalHeader, Characteristics, MajorLinkerVersion, MinorLinkerVersion, SizeOfCode, SizeOfInitializedData, SizeOfUninitializedData, AddressOfEntryPoint, BaseOfCode, BaseOfData, ImageBase, SectionAlignment, FileAlignment, MajorOperatingSystemVersion, MinorOperatingSystemVersion, MajorImageVersion, MinorImageVersion, MajorSubsystemVersion, MinorSubsystemVersion, SizeOfImage, SizeOfHeaders, CheckSum, Subsystem, DllCharacteristics, SizeOfStackReserve, SizeOfStackCommit, SizeOfHeapReserve, SizeOfHeapCommit, LoaderFlags, NumberOfRvaAndSizes, SectionsNb, SectionsMeanEntropy, SectionsMinEntropy, SectionsMaxEntropy, SectionsMeanRawsize, SectionsMinRawsize, SectionMaxRawsize, SectionsMeanVirtualsize, SectionsMinVirtualsize, SectionMaxVirtualsize, ImportsNbDLL, ImportsNb, ImportsNbOrdinal, ExportNb, ResourcesNb, ResourcesMeanEntropy, ResourcesMinEntropy, ResourcesMaxEntropy, ResourcesMeanSize, ResourcesMinSize, ResourcesMaxSize, LoadConfigurationSize, VersionInformationSize.</em></p>

<p>Many other feature could have been considered, for instance the number of suspicious function imported, or the number of section with a abnormal name, but it will be for another time (I ended the script a bit late in the night and forgot to implement those ¯\<em>(ツ)</em>/¯ ).</p>

<p>Regarding the dataset, we need to have an important number of both legitimate and malicious file:</p>

<ul>
<li>For legitimate file, I gathered all the Windows binaries (exe + dll) from Windows 2008, Windows XP and Windows 7 32 and 64 bits, so exactly 41323 binaries. It is not a perfect dataset as there is only Microsoft binaries and not binaries from application which could have different properties, but I did not find any easy way to gather easily a lot of legitimate binaries, so it will be enough for playing</li>
<li>Regarding malware, I used a part of <a href="https://virusshare.com/">Virus Share</a> collection by downloading one archive (the 134th) and kept only PE files (96724 different files).</li>
</ul>

<p>I used <a href="https://github.com/erocarrera/pefile">pefile</a> to extract all these features from the binaries and store them in a csv file (ugly code is <a href="https://github.com/Te-k/malware-classification/blob/master/generatedata.py">here</a>, <a href="https://github.com/Te-k/malware-classification/blob/master/data.csv">data</a> are here).</p>

<p>And here we are with a large CSV file (138048 lines) ready for playing!</p>

<h2 id="feature-selection">Feature Selection</h2>

<p>The idea of feature selection is to reduce the 54 features extracted to a smaller set of feature which are the most relevant for differentiating legitimate binaries from malware.</p>

<p>To play with the data, we will use <a href="http://pandas.pydata.org/">Pandas</a> and then <a href="http://scikit-learn.org/stable/index.html">Scikit</a> which largely uses the <a href="http://www.numpy.org/">numpy</a> library:</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span>data <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>read_csv(<span style="color: #4070a0">&#39;data.csv&#39;</span>, sep<span style="color: #666666">=</span><span style="color: #4070a0">&#39;|&#39;</span>)
legit_binaries <span style="color: #666666">=</span> data[<span style="color: #40a070">0</span>:<span style="color: #40a070">41323</span>]<span style="color: #666666">.</span>drop([<span style="color: #4070a0">&#39;legitimate&#39;</span>], axis<span style="color: #666666">=</span><span style="color: #40a070">1</span>)
malicious_binaries <span style="color: #666666">=</span> data[<span style="color: #40a070">41323</span>::]<span style="color: #666666">.</span>drop([<span style="color: #4070a0">&#39;legitimate&#39;</span>], axis<span style="color: #666666">=</span><span style="color: #40a070">1</span>)
</pre></div>

<p>So a first way of doing it manually could be to check the different values and see if there is a difference between the two groups. For instance, we can take the parameter FileAlignment (which defines the alignment of sections and is by default 0x200 bytes) and check the values :</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span>In [<span style="color: #40a070">8</span>]: legit_binaries[<span style="color: #4070a0">&#39;FileAlignment&#39;</span>]<span style="color: #666666">.</span>value_counts()
Out[<span style="color: #40a070">8</span>]:
<span style="color: #40a070">512</span>      <span style="color: #40a070">36843</span>
<span style="color: #40a070">4096</span>      <span style="color: #40a070">4313</span>
<span style="color: #40a070">128</span>         <span style="color: #40a070">89</span>
<span style="color: #40a070">32</span>          <span style="color: #40a070">40</span>
<span style="color: #40a070">65536</span>       <span style="color: #40a070">36</span>
<span style="color: #40a070">16</span>           <span style="color: #40a070">2</span>
Name: FileAlignment, dtype: int64

In [<span style="color: #40a070">9</span>]: malicious_binaries[<span style="color: #4070a0">&#39;FileAlignment&#39;</span>]<span style="color: #666666">.</span>value_counts()
Out[<span style="color: #40a070">9</span>]:
<span style="color: #40a070">512</span>     <span style="color: #40a070">94612</span>
<span style="color: #40a070">4096</span>     <span style="color: #40a070">2074</span>
<span style="color: #40a070">128</span>        <span style="color: #40a070">18</span>
<span style="color: #40a070">1024</span>       <span style="color: #40a070">15</span>
<span style="color: #40a070">64</span>          <span style="color: #40a070">2</span>
<span style="color: #40a070">32</span>          <span style="color: #40a070">1</span>
<span style="color: #40a070">16</span>          <span style="color: #40a070">1</span>
<span style="color: #40a070">2048</span>        <span style="color: #40a070">1</span>
Name: FileAlignment, dtype: int64
</pre></div>

<p>So if we remove the 20 malware having weird values here, there is not much difference on this value between the two groups, this parameter would not make a good feature for us.</p>

<p>On the other side, some values are clearly interesting like the max entropy of the sections which can be represented with an histogram:</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span>In [<span style="color: #40a070">12</span>]: plt<span style="color: #666666">.</span>hist([legit_binaries[<span style="color: #4070a0">&#39;SectionsMaxEntropy&#39;</span>], malicious_binaries[<span style="color: #4070a0">&#39;SectionsMaxEntropy&#39;</span>]], <span style="color: #007020">range</span><span style="color: #666666">=</span>[<span style="color: #40a070">0</span>,<span style="color: #40a070">8</span>], normed<span style="color: #666666">=</span><span style="color: #007020">True</span>, color<span style="color: #666666">=</span>[<span style="color: #4070a0">&quot;green&quot;</span>, <span style="color: #4070a0">&quot;red&quot;</span>],label<span style="color: #666666">=</span>[<span style="color: #4070a0">&quot;legitimate&quot;</span>, <span style="color: #4070a0">&quot;malicious&quot;</span>])
Out[<span style="color: #40a070">12</span>]:
([array([ <span style="color: #40a070">0.</span>        ,  <span style="color: #40a070">0.00120095</span>,  <span style="color: #40a070">0.00129333</span>,  <span style="color: #40a070">0.00914567</span>,  <span style="color: #40a070">0.08896238</span>,
        <span style="color: #40a070">0.04665213</span>,  <span style="color: #40a070">0.12609933</span>,  <span style="color: #40a070">0.55631513</span>,  <span style="color: #40a070">0.37580371</span>,  <span style="color: #40a070">0.04452738</span>]),
  array([  <span style="color: #40a070">9.04607814e-05</span>,   <span style="color: #40a070">0.00000000e+00</span>,   <span style="color: #40a070">1.29229688e-05</span>,
           <span style="color: #40a070">1.55075625e-04</span>,   <span style="color: #40a070">5.16918751e-04</span>,   <span style="color: #40a070">1.51198735e-03</span>,
           <span style="color: #40a070">6.04794938e-03</span>,   <span style="color: #40a070">8.64675840e-02</span>,   <span style="color: #40a070">3.81266348e-01</span>,
                                            <span style="color: #40a070">7.73930754e-01</span>])],
  array([ <span style="color: #40a070">0.</span> ,  <span style="color: #40a070">0.8</span>,  <span style="color: #40a070">1.6</span>,  <span style="color: #40a070">2.4</span>,  <span style="color: #40a070">3.2</span>,  <span style="color: #40a070">4.</span> ,  <span style="color: #40a070">4.8</span>,  <span style="color: #40a070">5.6</span>,  <span style="color: #40a070">6.4</span>,  <span style="color: #40a070">7.2</span>,  <span style="color: #40a070">8.</span> ]),
  <span style="color: #666666">&lt;</span>a <span style="color: #007020">list</span> of <span style="color: #40a070">2</span> Lists of Patches objects<span style="color: #666666">&gt;</span>)

In [<span style="color: #40a070">13</span>]: plt<span style="color: #666666">.</span>legend()
Out[<span style="color: #40a070">13</span>]: <span style="color: #666666">&lt;</span>matplotlib<span style="color: #666666">.</span>legend<span style="color: #666666">.</span>Legend at <span style="color: #40a070">0x7f15da65ee10</span><span style="color: #666666">&gt;</span>

In [<span style="color: #40a070">14</span>]: plt<span style="color: #666666">.</span>show()
</pre></div>


<figure >
    
        <img src="/media/sectionsmaxentropy.png" />
    
    
</figure>


<p>But there is a more efficient way of selecting features : some algorithms have been developed to identify the most interesting features and reduce the dimensionality of the data set (see <a href="http://scikit-learn.org/stable/modules/feature_selection.html">the Scikit page for Feature Selection</a>).</p>

<p>In our case, we will use the <a href="http://scikit-learn.org/stable/modules/feature_selection.html#tree-based-feature-selection">Tree-based feature selection</a>:</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span>In [<span style="color: #40a070">15</span>]: X <span style="color: #666666">=</span> data<span style="color: #666666">.</span>drop([<span style="color: #4070a0">&#39;Name&#39;</span>, <span style="color: #4070a0">&#39;md5&#39;</span>, <span style="color: #4070a0">&#39;legitimate&#39;</span>], axis<span style="color: #666666">=</span><span style="color: #40a070">1</span>)<span style="color: #666666">.</span>values

In [<span style="color: #40a070">16</span>]: y <span style="color: #666666">=</span> data[<span style="color: #4070a0">&#39;legitimate&#39;</span>]<span style="color: #666666">.</span>values

In [<span style="color: #40a070">17</span>]: fsel <span style="color: #666666">=</span> ske<span style="color: #666666">.</span>ExtraTreesClassifier()<span style="color: #666666">.</span>fit(X, y)

In [<span style="color: #40a070">20</span>]: model <span style="color: #666666">=</span> SelectFromModel(fsel, prefit<span style="color: #666666">=</span><span style="color: #007020">True</span>)

In [<span style="color: #40a070">21</span>]: X_new <span style="color: #666666">=</span> model<span style="color: #666666">.</span>transform(X)

In [<span style="color: #40a070">22</span>]: X<span style="color: #666666">.</span>shape
Out[<span style="color: #40a070">22</span>]: (<span style="color: #40a070">110258</span>, <span style="color: #40a070">54</span>)

In [<span style="color: #40a070">23</span>]: X_new<span style="color: #666666">.</span>shape
Out[<span style="color: #40a070">23</span>]: (<span style="color: #40a070">110258</span>, <span style="color: #40a070">11</span>)
</pre></div>

<p>So in this case, the algorithm selected 11 important features among the 54, and we can notice that indeed the SectionsMaxEntropy is selected but other features (like the Machine value) are surprisingly also good parameters for this classification :</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span>In [<span style="color: #40a070">1</span>]: nb_features <span style="color: #666666">=</span> X_new<span style="color: #666666">.</span>shape[<span style="color: #40a070">1</span>]

In [<span style="color: #40a070">2</span>]: indices <span style="color: #666666">=</span> np<span style="color: #666666">.</span>argsort(fsel<span style="color: #666666">.</span>feature_importances_)[::<span style="color: #666666">-</span><span style="color: #40a070">1</span>][:nb_features]

In [<span style="color: #40a070">3</span>]: <span style="color: #007020; font-weight: bold">for</span> f <span style="color: #007020; font-weight: bold">in</span> <span style="color: #007020">range</span>(nb_features):
   <span style="color: #666666">...</span>:         <span style="color: #007020; font-weight: bold">print</span>(<span style="color: #4070a0">&quot;</span><span style="color: #70a0d0; font-style: italic">%d</span><span style="color: #4070a0">. feature </span><span style="color: #70a0d0; font-style: italic">%s</span><span style="color: #4070a0"> (</span><span style="color: #70a0d0; font-style: italic">%f</span><span style="color: #4070a0">)&quot;</span> <span style="color: #666666">%</span> (f <span style="color: #666666">+</span> <span style="color: #40a070">1</span>, data<span style="color: #666666">.</span>columns[<span style="color: #40a070">2</span><span style="color: #666666">+</span>indices[f]], fsel<span style="color: #666666">.</span>feature_importances_[indices[f]]))
      <span style="color: #666666">...</span>:
      <span style="color: #40a070">1.</span> feature Characteristics (<span style="color: #40a070">0.187685</span>)
      <span style="color: #40a070">2.</span> feature Machine (<span style="color: #40a070">0.173019</span>)
      <span style="color: #40a070">3.</span> feature ImageBase (<span style="color: #40a070">0.099215</span>)
      <span style="color: #40a070">4.</span> feature Subsystem (<span style="color: #40a070">0.091090</span>)
      <span style="color: #40a070">5.</span> feature MajorSubsystemVersion (<span style="color: #40a070">0.077067</span>)
      <span style="color: #40a070">6.</span> feature SectionsMaxEntropy (<span style="color: #40a070">0.046552</span>)
      <span style="color: #40a070">7.</span> feature SizeOfOptionalHeader (<span style="color: #40a070">0.040004</span>)
      <span style="color: #40a070">8.</span> feature ResourcesMaxEntropy (<span style="color: #40a070">0.035633</span>)
      <span style="color: #40a070">9.</span> feature VersionInformationSize (<span style="color: #40a070">0.027091</span>)
      <span style="color: #40a070">10.</span> feature SectionsNb (<span style="color: #40a070">0.020562</span>)
      <span style="color: #40a070">11.</span> feature DllCharacteristics (<span style="color: #40a070">0.018640</span>)
</pre></div>

<h2 id="selection-of-the-classification-algorithm">Selection of the Classification Algorithm</h2>

<p>The best classification algorithm depends on many parameters and some of them (like SVM) have a lot of different parameters and can be difficult to correctly configure. So I used a simple option: I tested some of them with default parameters and selected the best one (I removed SVM because it does not handle well dataset with many features):</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span>algorithms <span style="color: #666666">=</span> {
        <span style="color: #4070a0">&quot;DecisionTree&quot;</span>: tree<span style="color: #666666">.</span>DecisionTreeClassifier(max_depth<span style="color: #666666">=</span><span style="color: #40a070">10</span>),
        <span style="color: #4070a0">&quot;RandomForest&quot;</span>: ske<span style="color: #666666">.</span>RandomForestClassifier(n_estimators<span style="color: #666666">=</span><span style="color: #40a070">50</span>),
        <span style="color: #4070a0">&quot;GradientBoosting&quot;</span>: ske<span style="color: #666666">.</span>GradientBoostingClassifier(n_estimators<span style="color: #666666">=</span><span style="color: #40a070">50</span>),
        <span style="color: #4070a0">&quot;AdaBoost&quot;</span>: ske<span style="color: #666666">.</span>AdaBoostClassifier(n_estimators<span style="color: #666666">=</span><span style="color: #40a070">100</span>),
        <span style="color: #4070a0">&quot;GNB&quot;</span>: GaussianNB()
    }

results <span style="color: #666666">=</span> {}
<span style="color: #007020; font-weight: bold">print</span>(<span style="color: #4070a0">&quot;</span><span style="color: #4070a0; font-weight: bold">\n</span><span style="color: #4070a0">Now testing algorithms&quot;</span>)
<span style="color: #007020; font-weight: bold">for</span> algo <span style="color: #007020; font-weight: bold">in</span> algorithms:
    clf <span style="color: #666666">=</span> algorithms[algo]
    clf<span style="color: #666666">.</span>fit(X_train, y_train)
    score <span style="color: #666666">=</span> clf<span style="color: #666666">.</span>score(X_test, y_test)
    <span style="color: #007020; font-weight: bold">print</span>(<span style="color: #4070a0">&quot;</span><span style="color: #70a0d0; font-style: italic">%s</span><span style="color: #4070a0"> : </span><span style="color: #70a0d0; font-style: italic">%f</span><span style="color: #4070a0"> </span><span style="color: #70a0d0; font-style: italic">%%</span><span style="color: #4070a0">&quot;</span> <span style="color: #666666">%</span> (algo, score<span style="color: #666666">*</span><span style="color: #40a070">100</span>))
    results[algo] <span style="color: #666666">=</span> score

winner <span style="color: #666666">=</span> <span style="color: #007020">max</span>(results, key<span style="color: #666666">=</span>results<span style="color: #666666">.</span>get)
<span style="color: #007020; font-weight: bold">print</span>(<span style="color: #4070a0">&#39;</span><span style="color: #4070a0; font-weight: bold">\n</span><span style="color: #4070a0">Winner algorithm is </span><span style="color: #70a0d0; font-style: italic">%s</span><span style="color: #4070a0"> with a </span><span style="color: #70a0d0; font-style: italic">%f</span><span style="color: #4070a0"> </span><span style="color: #70a0d0; font-style: italic">%%</span><span style="color: #4070a0"> success&#39;</span> <span style="color: #666666">%</span> (winner, results[winner]<span style="color: #666666">*</span><span style="color: #40a070">100</span>))
</pre></div>

<p>Let&rsquo;s run it:</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span>Now testing algorithms
GNB : <span style="color: #40a070">69.478450</span> <span style="color: #666666">%</span>
DecisionTree : <span style="color: #40a070">98.960522</span> <span style="color: #666666">%</span>
RandomForest : <span style="color: #40a070">99.351684</span> <span style="color: #666666">%</span>
AdaBoost : <span style="color: #40a070">98.558493</span> <span style="color: #666666">%</span>
GradientBoosting : <span style="color: #40a070">98.761318</span> <span style="color: #666666">%</span>

Winner algorithm <span style="color: #007020; font-weight: bold">is</span> RandomForest <span style="color: #007020; font-weight: bold">with</span> a <span style="color: #40a070">99.351684</span> <span style="color: #666666">%</span> success
</pre></div>

<p>If we recompute the false positive/false negative rate on the test data, we obtain :</p>

<ul>
<li>False positive : 0.568241 %</li>
<li>False negative : 0.830565 %</li>
</ul>

<p>So it&rsquo;s a 99.35% success, so more than the <a href="https://www.blackhat.com/docs/webcast/TowardsClassificationofPolymorphicMalware-Final.pdf">Adobe</a> work (98.21%) but still with the RandomForest algorithm.</p>

<p>The whole code for feature selection and algorithm test is available <a href="https://github.com/Te-k/malware-classification/blob/master/learning.py">here</a></p>

<h2 id="reuse-the-algorithm">Reuse the algorithm</h2>

<p>So now we want to reuse this algorithms for detection, we can just save the object and the feature list :</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span>joblib<span style="color: #666666">.</span>dump(algorithms[winner], <span style="color: #4070a0">&#39;classifier/classifier.pkl&#39;</span>)
<span style="color: #007020">open</span>(<span style="color: #4070a0">&#39;classifier/features.pkl&#39;</span>, <span style="color: #4070a0">&#39;w&#39;</span>)<span style="color: #666666">.</span>write(pickle<span style="color: #666666">.</span>dumps(features))
</pre></div>

<p>I have then implemented a <a href="https://github.com/Te-k/malware-classification/blob/master/checkpe.py">simple tool</a> which load the feature list and the classifier, extract the PE feature and predict if a binary is malicious or not:</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span><span style="color: #666666">&gt;</span> python2 checkpe<span style="color: #666666">.</span>py <span style="color: #666666">~/</span>virusshare<span style="color: #666666">/</span>VirusShare_000b296200f7b8fffbc584f3eac864b2
The <span style="color: #007020">file</span> VirusShare_000b296200f7b8fffbc584f3eac864b2 <span style="color: #007020; font-weight: bold">is</span> malicious
<span style="color: #666666">&gt;</span> python2 checkpe<span style="color: #666666">.</span>py <span style="color: #666666">~/</span>legitimate<span style="color: #666666">/</span>explorer<span style="color: #666666">.</span>exe
The <span style="color: #007020">file</span> explorer<span style="color: #666666">.</span>exe <span style="color: #007020; font-weight: bold">is</span> legitimate
</pre></div>

<p>As I like the new <a href="https://manalyzer.org/">Manalyzer</a> platform, I have also developed <a href="https://github.com/Te-k/malware-classification/blob/master/checkmanalyzer.py">a script</a> which download the PE properties and predict if the binary is legitimate of not:</p>
<div class="highlight" style="background: #f0f0f0"><pre style="line-height: 125%"><span></span><span style="color: #666666">&gt;</span>python2 checkmanalyzer<span style="color: #666666">.</span>py https:<span style="color: #666666">//</span>manalyzer<span style="color: #666666">.</span>org<span style="color: #666666">/</span>report<span style="color: #666666">/</span>a9ea61c5ae7eab02c63955336a7c7efe
The <span style="color: #007020">file</span> a9ea61c5ae7eab02c63955336a7c7efe <span style="color: #007020; font-weight: bold">is</span> legitimate
<span style="color: #666666">&gt;</span> python2 checkmanalyzer<span style="color: #666666">.</span>py https:<span style="color: #666666">//</span>manalyzer<span style="color: #666666">.</span>org<span style="color: #666666">/</span>report<span style="color: #666666">/</span><span style="color: #40a070">9</span>c5c27494c28ed0b14853b346b113145
The <span style="color: #007020">file</span> <span style="color: #40a070">9</span>c5c27494c28ed0b14853b346b113145 <span style="color: #007020; font-weight: bold">is</span> malicious
</pre></div>

<h2 id="why-it-s-not-enough">Why it&rsquo;s not enough?</h2>

<p>First, a bit of vocabulary for measuring IDS accuracy (taken from <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">Wikipedia</a>):</p>

<ul>
<li><strong>Sensitivity</strong> : the proportion of positives identified as such (or true positive rate)</li>
<li><strong>Specificity</strong> : the proportion of negatives correctly identified as such (or true negative)</li>
<li><strong>False Positive Rate</strong> (FPR) : the proportion of events badly identified as positive over the total number of negatives</li>
<li><strong>False Negative Rate</strong> (FNR) : the proportion of events badly identified as negative over the total number of positives</li>
</ul>

<p>So why 99.35% is not enough?</p>

<p>Because you can&rsquo;t just consider the sensitivity/specificity of the algorithm, you have to consider the malicious over legitimate traffic ratio to understand how many alerts will be generated by the IDS. And this ratio is extremely low.</p>

<p>Let&rsquo;s consider the you have 1 malicious event every 10 000 event (it&rsquo;s a really high ratio) and 1 000 000 events per day, you will have :</p>

<ul>
<li>100 malicious events, 99 identified by the tool and 1 false negative (0.83% FNR but let&rsquo;s consider 1% here)</li>
<li>999 900 legitimate events, around 6499 identified as malicious (0.65% FPR)</li>
</ul>

<p>So in the end, <strong>the analyst would received 6598 alerts per day with only 99 true positive in it (1.5%)</strong>. Your IDS is useless here. (Out of curiosity, the same problem applies when <a href="http://www.jaddo.fr/2016/06/19/et-mes-fesses-elles-sont-roses-mes-fesses/">detecting cancer at large scale</a> (in French))</p>

<p>If we take our example, a standard Windows 7 install has around 15000 binary files (it seems to be very different depending on the version, but let&rsquo;s say 15000), which means that in average 97 files would be detected incorrectly as malicious. And that&rsquo;s a bad antivirus.</p>

<h2 id="conclusion">Conclusion</h2>

<p>So it was a fun example of machine learning utilization. I like how Pandas and Scikit make machine learning easy to use in python (and Scikit is really well explained and documented!). I was really surprised to have such good results without any effort for configuring the algorithm specifically for this context, and it shows that the Adobe tool is not as good as I thought.</p>

<p>Still, it is interesting to remind the IDS problem and show it concretely (just after self-congratulation for such a good sensitivity :).</p>

<p>If you have any question, comment or idea to continue playing with this dataset, let me know on <a href="https://twitter.com/tenacioustek">Twitter</a>.</p>

<p>Here are some nice references on this topic:</p>

<ul>
<li><a href="http://pandas.pydata.org/pandas-docs/stable/10min.html">Learning Pandas in 10 minutes</a></li>
<li><a href="https://blog.socialcops.com/engineering/machine-learning-python">Would You Survive the Titanic? A Guide to Machine Learning in Python</a></li>
<li><a href="http://scikit-learn.org/stable/index.html">Scikit Learn</a></li>
</ul>

<p>Adéu!</p>

<p><em>Edit 21/07/16: improved the dataset with more legitimate binaries. Updated the results</em>
<em>Edit 02/08/16: explained why it&rsquo;s not enough</em></p>

<p><em>This article was written mainly while listening Glenn Gould <a href="https://www.youtube.com/watch?v=Ah392lnFHxM">Goldberg Variations (1955)</a></em></p>

                
                    
                
                

                


            </div>
        </div>
    </body>
</html>

